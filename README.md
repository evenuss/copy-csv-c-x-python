# ğŸš€ C vs. Python: Inserting 1 Million Rows into PostgreSQL  

This project compares the performance of **C** and **Python** when inserting 1 million rows into a PostgreSQL database using the `COPY` command.  

## ğŸ“Š Experiment Results  

| Language | Time Taken |
|----------|-----------|
| **C** | **0.28 seconds** â© |
| **Python** | **4.24 seconds** ğŸ |

## ğŸ“Œ Why the Difference?  

âœ… **C is faster because:**  
- Low-level memory management  
- No runtime overhead like Python  
- No Global Interpreter Lock (GIL)  

ğŸ **Python is slower, but offers:**  
- Simplicity and readability  
- Rich ecosystem and libraries  
- Easier debugging and maintenance  

## ğŸ› ï¸ How to Run the Experiment  

### 1ï¸âƒ£ Setup PostgreSQL  
Ensure you have PostgreSQL installed and running. Update the database credentials in the code if necessary.  

### 2ï¸âƒ£ Generate Dummy Data  
Before inserting data, generate the CSV file using:  
```bash
python generate.py
```
This will create a file named `dummy_data.csv` with 1 million rows.  

### 3ï¸âƒ£ Run the C Implementation  
Compile and execute the C program:  
```bash
gcc -o insert_postgres insert_postgres.c -lpq
./insert_postgres
```

### 4ï¸âƒ£ Run the Python Implementation  
Execute the Python script:  
```bash
python insert_postgres.py
```

### 5ï¸âƒ£ Check Database  
Verify that the data is inserted properly in PostgreSQL using:  
```sql
SELECT COUNT(*) FROM users;
```

## ğŸ“Œ Conclusion  
If raw performance is a priority, **C** is the winner. However, for ease of development and maintainability, **Python** remains a strong choice.  
